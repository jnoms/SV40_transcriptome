#!/usr/bin/env python3

import pathlib
import os
import argparse
import gzip
import sys
import io
import numpy as np
import pandas as pd

from utils.misc_utils import open_file, parse_bed_blocks, span_file_to_tx_class_dict

def get_args():
    parser = argparse.ArgumentParser(description="""
            The purpose of this script is to process DIMAOND alignments of
            predicted ORFs. In addition, information on the transcript
            that contains each ORF is also annotated (e.g. transcript class).
            Splicing information from BED files is used to note which ORFs
            contain a splice.
            """)

    # Required arguments
    parser.add_argument(
        '-d',
        '--in_diamond',
        type=str,
        required=True,
        help='''
        Path to the input DIAMOND file.
        '''
    )
    parser.add_argument(
        '-b',
        '--in_bed',
        type=str,
        required=True,
        help='''
        Path to the BED file which was used to generate the FASTA from which
        ORFs were predicted.
        '''
    )

    # Optional arguments
    parser.add_argument(
        '-s',
        '--in_spans',
        type=str,
        required=False,
        default="no",
        help='''
        Path to the span file, generated by bed_to_span.py, generally from the
        slid BED.
        '''
    )
    parser.add_argument(
        '-o',
        '--out_report',
        type=str,
        required=False,
        default="no",
        help='''
        Path to the output report. Columns are as follows:
        - tx_name: Name of transcript the ORF was predicted from
        - tx_class: Transcript class
        - tx_class_count: Number of transcripts in its transcript class
        - ORF_name: Full ORF name (identical to ORF fasta header)
        - ORF_number: Order of ORF on the tx (e.g. if 1, ORF is first).
            This is calculated based on ORF coordinates. NOTE - if these data
            are from Illumina, or if the prodigal ORFs were filtered to only
            keep spliced ORFs prior to generating the ORF fastas, this number
            won't be relevant. Mostly relevant for full dRNAseq reads.
        - ORF_start: Start postion on the transcript
        - ORF_end: End position on the transcript (includes stop codon)
        - ORF_AA_len: Length of the ORF AA sequence.
        - ORF_type: c (canonical), v (variant), or u (unknown)
        - ORF_alignment: If the ORF is canonical, this is sseqid. If unknown, this
            is blank. If variant, this is sseqid-qstart-qend-sstart-send.
        - ORF_splice: 0 = unspliced, 1 = spliced (e.g. the ORF was predicted on
            the transcript over a splice site.)
        '''
    )

    # optional arguments
    parser.add_argument(
        '-D',
        '--diamond_fields',
        type=str,
        required=False,
        default="6 qseqid sseqid evalue bitscore pident length qlen slen qstart qend sstart send",
        help='''
        This should be equal to the outformat used in DIAMOND. Required fields
        are qseqid, sseqid, length, qlen, slen, qstart, qend, sstart, send.
        '''
    )
    parser.add_argument(
        '-C',
        '--span_columns',
        type=str,
        required=False,
        default="name start end strand span_type tx_start tx_end tx_class tx_class_count",
        help='''
        Space-delimited list of the columns that are in the input spans file.
        '''
    )

    args = parser.parse_args()

    # Format fields inputs
    args.diamond_fields = args.diamond_fields.split(" ")
    args.diamond_fields = [s for s in args.diamond_fields if s != "6"]
    args.span_columns = args.span_columns.split(" ")

    # Validate args
    for required in ["qseqid", "sseqid", "length", "qlen", "slen", "qstart", "qend", "sstart", "send"]:
        if not required in args.diamond_fields:
            msg = "Missing at least one required diamond_field: {}".format(required)
            raise ValueError(msg)

    return args

#------------------------------------------------------------------------------#
# ORF object
#------------------------------------------------------------------------------#
class orf_object:
    """
    Holds information for an ORF.
    """

    def __init__(self, tx_name, tx_class, tx_class_count, ORF_name, ORF_number, ORF_start, ORF_end, ORF_AA_len, ORF_strand,
                 ORF_type, alignment_string, splice_status):

        # Transcript information
        self.tx_name = tx_name
        self.tx_class = tx_class
        self.tx_class_count = tx_class_count

        # ORF information
        self.ORF_name = ORF_name
        self.ORF_number = ORF_number
        self.ORF_start = ORF_start
        self.ORF_end = ORF_end
        self.ORF_AA_len = ORF_AA_len
        self.ORF_type = ORF_type
        self.alignment_string = alignment_string
        self.splice_status = splice_status

    def output_line(self):
        output = "{} {} {} {} {} {} {} {} {} {} {}\n".format(self.tx_name, self.tx_class, self.tx_class_count,
                                                          self.ORF_name, self.ORF_number, self.ORF_start,
                                                   self.ORF_end, self.ORF_AA_len, self.ORF_type,
                                                   self.alignment_string, self.splice_status)
        output = output.replace(" ", "\t")
        return output

#------------------------------------------------------------------------------#
# Functions for this script
#------------------------------------------------------------------------------#
def simplify_tx_name(tx_name):
    """
    The qseqid from DIAMOND is essentially the transcript name, but it has been transformed
    significantly.

    1) The called ORF is at the end after the xxx
    2) If the ORFs were generated from bedtools, there will be
       an :: followed by accession:tx_start-tx_end
    3) If the bed was processed to contain representatives, the
       transcripts were labled with __tx-class__tx-class-counts

    When looking up transcript_names, will by default strip away all of this information.
    """
    # 1) Remove the ORF info, which is after xxx
    tx_name = tx_name.split("xxx")[0]

    # 2) Filter off the bedtools information
    tx_name = tx_name.split("::")[0]

    # 3) Filter off the tx_class information
    tx_name = tx_name.split("__")[0]

    return tx_name

def simplify_tx_name_on_dict(in_dict):
    """
    Appliex simplify_tx_name on a dictionary.
    """
    in_dict = in_dict.copy()

    for key in list(in_dict.keys()):

        simplified_key = simplify_tx_name(key)

        # If already simple, move on!
        if simplified_key == key:
            continue

        in_dict[simplified_key] = in_dict[key]
        del in_dict[key]

    return in_dict


def diamond_to_dict(in_diamond, diamond_fields):
    """
    Input:
        - in_diamond: Path to diamond file

    Output:
        - Dictionary of structure simplified_tx_name:LIST of all alignments of all ORFs
          in the transcript.
          Notes about the list - each item in the list is a tab-split LINE from the DIAMOND
          file. Some ORFs have multiple alignments so are present multiple times.
    """
    diamond_results = dict()
    with open_file(in_diamond) as infile:

        for line in infile:

            # Parse each line
            line = line.rstrip("\n").split("\t")

            # Find the transcript name
            tx_name = simplify_tx_name(line[diamond_fields.index("qseqid")])

            # Write to dictionary
            if tx_name not in diamond_results:
                diamond_results[tx_name] = []

            diamond_results[tx_name].append(line)

    return diamond_results

def get_orf_order(diamond_results, diamond_fields):
    orf_order = dict()
    for transcript, diamond_alignments in diamond_results.items():

        # First, find all ORFs for a transcript. Using a set because
        # ORFs can have multiple alignments
        ORF_list = set()
        for diamond_alignment in diamond_alignments:
            ORF = diamond_alignment[diamond_fields.index("qseqid")]
            ORF_list.add(ORF)

        # For each ORF in the ORF list, sort them by their start position
        ORF_list = list(ORF_list)
        ORF_list = sorted(ORF_list, key = lambda x: int(x.split("xxx")[1].split("_")[0]))

        # Add each ORF to orf_order using their index... orf_order will start at 1.
        for i, ORF in enumerate(ORF_list):
            orf_order[ORF] = i + 1
    return orf_order


def format_alignment_dict(alignments, diamond_fields):
    """
    Input:
        - Alignments: list of lists, where each sublist is a tab-split line
        from diamond file. The qseqid is the ORF title. Some ORFs have multiple
        alignments
    Output:
        - Dictionary of structure ORF:alignment, where the alignment with the
        longest alignment length was kept.
    """

    # Parse alignments into separate dictionary entries, one per ORF
    # ORF:[alignment1, alignment2, ...]
    alignment_dict = dict()
    for alignment in alignments:
        ORF = alignment[0]
        if not ORF in alignment_dict:
            alignment_dict[ORF] = []
        alignment_dict[ORF].append(alignment)


    # Keep longest alignment if there are multiple
    filtered_alignment_dict = dict()
    for ORF, alignments in alignment_dict.items():
        alignment_lengths = [alignment[diamond_fields.index("length")] for alignment in alignments]
        alignment_lengths = [int(alignment_length) for alignment_length in alignment_lengths] # convert to interger so max() works
        alignments = [alignment for alignment in alignments if int(alignment[diamond_fields.index("length")]) == max(alignment_lengths)]
        filtered_alignment_dict[ORF] = alignments[0]

    return filtered_alignment_dict


def parse_alignment_information(alignment, diamond_fields):
    """
    Parses a single alignment (a tab-split list from a diamond line)
    and returns a tuple of structure (class, alignment_string).

    - Class is either "c", "v", or "n" (canonical, variant, novel
    - alignment string is blank for n, sseqid for c, and
      sseqid-qstart-qend-sstart-send for v.
    """

    sseqid = alignment[diamond_fields.index("sseqid")]
    qlen = alignment[diamond_fields.index("qlen")]
    slen = alignment[diamond_fields.index("slen")]
    qstart = alignment[diamond_fields.index("qstart")]
    qend = alignment[diamond_fields.index("qend")]
    sstart = alignment[diamond_fields.index("sstart")]
    send = alignment[diamond_fields.index("send")]

    # Determine class
    if sseqid == "*":
        return "u", ""
        pass #TEMP ---------------

    # Determine if canonical
    if qlen == slen and qstart == sstart and qend == send:
        return "c", sseqid

    # Otherwise, list as variant and give alignment information
    return "v", "{}-{}-{}-{}-{}".format(sseqid, qstart, qend, sstart, send)

def get_splice_status(start, end, bed_blocks):
    start = int(start)
    end = int(end)

    for block in bed_blocks:
        if start <= block <= end:
            return 1

    return 0


def main():

    # Sort out the arguments
    #--------------------------------------------------------------------#
    args = get_args()
    in_diamond = args.in_diamond
    in_bed = args.in_bed
    in_spans = args.in_spans
    out_report = args.out_report
    diamond_fields = args.diamond_fields
    span_columns = args.span_columns

    # Main
    #--------------------------------------------------------------------#
    print("{}: Starting script".format(sys.argv[0]))

    # Parse the bed to get the blocks (splice points) for each transcript
    # tx_name: [splice_site1, splice_site2, ...]
    bed_blocks_dict = parse_bed_blocks(in_bed)
    bed_blocks_dict = simplify_tx_name_on_dict(bed_blocks_dict)

    # Parse spans to find the tx_class for each transcript
    # tx_name: (tx_class, tx_class_count)
    tx_class_dict = span_file_to_tx_class_dict(in_spans, span_columns)

    # Parse DIAMOND file into a dictionary, where keys are transcript names, values are the tab-split lines
    # tx_name: [[ORFa alignment], [ORFb alignment]...] - note that some ORFs have multiple alignments.
    diamond_results = diamond_to_dict(in_diamond, diamond_fields)

    # Make a dictionary of ORF:ORF_NUMBER (e.g. order on the transcript)
    # For illumina, this will be "of spliced orfs" if there was filtration
    # prior to running DIAMOND.
    # ORF_name: order
    orf_order_dict = get_orf_order(diamond_results, diamond_fields)

    # Parse through all ORFs and load ORF objects
    ORF_object_dict = dict()
    for tx_name, ORF_alignments in diamond_results.items():

        # Parse bed blocks and tx_class for each transcript
        bed_blocks = bed_blocks_dict[tx_name]
        tx_class, tx_class_count = tx_class_dict[tx_name]

        # Derive the "simple" tx_name which is the name of the read
        simple_tx_name = simplify_tx_name(tx_name)

        # Parse alignments into separate dictionary entries, one per ORF
        # ORF:alignment - if multiple alignments, keeping just the longest
        alignment_dict = format_alignment_dict(ORF_alignments, diamond_fields)

        # Iterate over each ORF to generate ORF objects
        for ORF, alignment in alignment_dict.items():

            # Determine if ORF is spliced
            ORF_start, ORF_end, ORF_strand = ORF.split("xxx")[-1].split("_")
            splice_status = get_splice_status(ORF_start, ORF_end, bed_blocks)

            # ORF name...
            ORF_name = alignment[diamond_fields.index("qseqid")]

            # Get type and alignment string
            ORF_type, alignment_string = parse_alignment_information(alignment, diamond_fields)

            # Get ORF order
            orf_order = orf_order_dict[ORF]

            # ORF length
            ORF_AA_len = int((int(ORF_end) - int(ORF_start) + 1 - 3)/3) # adjust to end of codon, then subtract stop codon

            # Now, we finally have all information needed for an ORF object
            ORF_object_dict[ORF] = orf_object(tx_name, tx_class, tx_class_count, ORF_name, orf_order, ORF_start, ORF_end, ORF_AA_len, ORF_strand,
                       ORF_type, alignment_string, splice_status)

    # Write output
    # Make output directories if needed
    out_dir = os.path.dirname(out_report)
    pathlib.Path(out_dir).mkdir(parents=True, exist_ok=True)

    output_str = "tx_name tx_class tx_class_count ORF_name ORF_number ORF_start ORF_end ORF_AA_len ORF_type ORF_alignment ORF_splice\n".replace(" ", "\t")
    for ORF, ORF_object in ORF_object_dict.items():
        output_str += ORF_object.output_line()

    # Convert to dataframe so I can sort appropriately
    output_str = io.StringIO(output_str)
    output_df = pd.read_csv(output_str, sep="\t")

    output_df.sort_values(by=['tx_name', 'ORF_number']).to_csv(out_report, sep="\t", index=False)

    print("{}: Finished".format(sys.argv[0]))

if __name__ == '__main__':
    main()
